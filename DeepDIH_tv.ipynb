{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch  \n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import PIL.Image as Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "TORCH_CUDA_ARCH_LIST=\"8.6\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phase Unwap and fft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unwrap(x):\n",
    "    y = x % (2 * np.pi)\n",
    "    return torch.where(y > np.pi, 2*np.pi - y, y)\n",
    "\n",
    "def fft2dc(x):\n",
    "    return np.fft.fftshift(np.fft.fft2(x))\n",
    "  \n",
    "def ifft2dc(x):\n",
    "    return np.fft.ifft2(np.fft.fftshift(x))\n",
    "\n",
    "def Phase_unwrapping(in_):\n",
    "    f = np.zeros((1000,1000))\n",
    "    for ii in range(1000):\n",
    "        for jj in range(1000):\n",
    "            x = ii - 1000/2\n",
    "            y = jj - 1000/2\n",
    "            f[ii,jj] = x**2 + y**2\n",
    "    a = ifft2dc(fft2dc(np.cos(in_)*ifft2dc(fft2dc(np.sin(in_))*f))/(f+0.000001))\n",
    "    b = ifft2dc(fft2dc(np.sin(in_)*ifft2dc(fft2dc(np.cos(in_))*f))/(f+0.000001))\n",
    "    out = np.real(a - b)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spherical light function\n",
    "Nx, Ny : hologram size\n",
    "z : object-sensor distance\n",
    "wavelength: wavelength of light\n",
    "deltaX, deltaY : sensor size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propagator(Nx,Ny,z,wavelength,deltaX,deltaY):\n",
    "    k = 1/wavelength\n",
    "    x = np.expand_dims(np.arange(np.ceil(-Nx/2),np.ceil(Nx/2),1)*(1/(Nx*deltaX)),axis=0)\n",
    "    y = np.expand_dims(np.arange(np.ceil(-Ny/2),np.ceil(Ny/2),1)*(1/(Ny*deltaY)),axis=1)\n",
    "    y_new = np.repeat(y,Nx,axis=1)\n",
    "    x_new = np.repeat(x,Ny,axis=0)\n",
    "    kp = np.sqrt(y_new**2+x_new**2)\n",
    "    term=k**2-kp**2\n",
    "    term=np.maximum(term,0) \n",
    "    phase = np.exp(1j*2*np.pi*z*np.sqrt(term))\n",
    "    return phase\n",
    "\n",
    "# um\n",
    "Nx = 1000\n",
    "Ny = 1000\n",
    "z = 857\n",
    "wavelength = 0.635\n",
    "deltaX = 1.67\n",
    "deltaY = 1.67"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('./Image1.bmp')\n",
    "\n",
    "# pytorch provides a function to convert PIL images to tensors.\n",
    "pil2tensor = transforms.ToTensor()\n",
    "tensor2pil = transforms.ToPILImage()\n",
    "\n",
    "tensor_img = pil2tensor(img)\n",
    "\n",
    "g = tensor_img.numpy()\n",
    "g = np.sqrt(g)\n",
    "g = (g-np.min(g))/(np.max(g)-np.min(g))\n",
    "\n",
    "plt.figure(figsize=(20,15))\n",
    "plt.imshow(np.squeeze(g), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back-propogation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase = propagator(Nx,Ny,z,wavelength,deltaX,deltaY)\n",
    "eta = np.fft.ifft2(np.fft.fft2(g)*np.fft.fftshift(np.conj(phase)))\n",
    "plt.figure(figsize=(20,15))\n",
    "plt.imshow(np.squeeze(np.abs(eta)), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_holo = ifft2dc(np.fft.fft2(eta)*np.fft.fftshift(phase))\n",
    "plt.figure(figsize=(20,15))\n",
    "plt.imshow(np.squeeze(np.abs(new_holo)), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RECLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RECLoss,self).__init__()\n",
    "        self.Nx = 1000\n",
    "        self.Ny = 1000\n",
    "        self.z = 857\n",
    "        self.wavelength = 0.635\n",
    "        self.deltaX = 1.67\n",
    "        self.deltaY = 1.67\n",
    "        self.prop = self.propagator(self.Nx,self.Ny,self.z,self.wavelength,self.deltaX,self.deltaY)\n",
    "        self.prop = self.prop.cuda()\n",
    "\n",
    "    def propagator(self,Nx,Ny,z,wavelength,deltaX,deltaY):\n",
    "        k = 1/wavelength\n",
    "        x = np.expand_dims(np.arange(np.ceil(-Nx/2),np.ceil(Nx/2),1)*(1/(Nx*deltaX)),axis=0)\n",
    "        y = np.expand_dims(np.arange(np.ceil(-Ny/2),np.ceil(Ny/2),1)*(1/(Ny*deltaY)),axis=1)\n",
    "        y_new = np.repeat(y,Nx,axis=1)\n",
    "        x_new = np.repeat(x,Ny,axis=0)\n",
    "        kp = np.sqrt(y_new**2+x_new**2)\n",
    "        term=k**2-kp**2\n",
    "        term=np.maximum(term,0) \n",
    "        phase = np.exp(1j*2*np.pi*z*np.sqrt(term))\n",
    "        return torch.from_numpy(np.concatenate([np.real(phase)[np.newaxis,:,:,np.newaxis], np.imag(phase)[np.newaxis,:,:,np.newaxis]], axis = 3))\n",
    "   \n",
    "\n",
    "    def roll_n(self, X, axis, n):\n",
    "        f_idx = tuple(slice(None, None, None) if i != axis else slice(0, n, None) for i in range(X.dim()))\n",
    "        b_idx = tuple(slice(None, None, None) if i != axis else slice(n, None, None) for i in range(X.dim()))\n",
    "        front = X[f_idx]\n",
    "        back = X[b_idx]\n",
    "        return torch.cat([back, front], axis)\n",
    "\n",
    "    def batch_fftshift2d(self, x):\n",
    "        real, imag = torch.unbind(x, -1)\n",
    "        for dim in range(1, len(real.size())):\n",
    "            n_shift = real.size(dim)//2\n",
    "            if real.size(dim) % 2 != 0:\n",
    "                n_shift += 1  # for odd-sized images\n",
    "            real = self.roll_n(real, axis=dim, n=n_shift)\n",
    "            imag = self.roll_n(imag, axis=dim, n=n_shift)\n",
    "        return torch.stack((real, imag), -1)  # last dim=2 (real&imag)\n",
    "\n",
    "    def batch_ifftshift2d(self,x):\n",
    "        real, imag = torch.unbind(x, -1)\n",
    "        for dim in range(len(real.size()) - 1, 0, -1):\n",
    "            real = self.roll_n(real, axis=dim, n=real.size(dim)//2)\n",
    "            imag = self.roll_n(imag, axis=dim, n=imag.size(dim)//2)\n",
    "        return torch.stack((real, imag), -1)  # last dim=2 (real&imag)\n",
    "    \n",
    "    def complex_mult(self, x, y):\n",
    "        real_part = x[:,:,:,0]*y[:,:,:,0]-x[:,:,:,1]*y[:,:,:,1]\n",
    "        real_part = real_part.unsqueeze(3)\n",
    "        imag_part = x[:,:,:,0]*y[:,:,:,1]+x[:,:,:,1]*y[:,:,:,0]\n",
    "        imag_part = imag_part.unsqueeze(3)\n",
    "        return torch.cat((real_part, imag_part), 3)\n",
    "\n",
    "    def forward(self,x,y):\n",
    "        batch_size = x.size()[0]\n",
    "        \n",
    "        x = x.squeeze(2)\n",
    "        y = y.squeeze(2)\n",
    "        x = x.permute([0,2,3,1])\n",
    "        y = y.permute([0,2,3,1])\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        cEs = self.batch_fftshift2d(torch.fft(x,3,normalized=True))\n",
    "        cEsp = self.complex_mult(cEs,self.prop)\n",
    "        \n",
    "        \n",
    "        # forward propogate\n",
    "        # reconstrut_freq = torch.log(torch.abs(self.batch_fftshift2d(torch.fft(x,3,normalized=True)) )+1e-5)\n",
    "        reconstrut_freq = cEsp\n",
    "        reconstrut_freq=(reconstrut_freq-torch.min(reconstrut_freq))/(torch.max(reconstrut_freq)-torch.min(reconstrut_freq))\n",
    "        \n",
    "        \n",
    "        \n",
    "        capture_freq =  torch.log( torch.abs(self.batch_fftshift2d(torch.fft(y,3,normalized=True) ))+1e-5)\n",
    "        capture_freq=(capture_freq-torch.min(capture_freq))/(torch.max(capture_freq)-torch.min(capture_freq))\n",
    "        \n",
    "        h_x = x.size()[1]\n",
    "        w_x = x.size()[2]\n",
    "        \n",
    "        \n",
    "       \n",
    "        \n",
    "        \n",
    "        h_tv_x = torch.pow((reconstrut_freq[:,1:,:,:]-reconstrut_freq[:,:h_x-1,:,:]),2).sum()\n",
    "        w_tv_x = torch.pow((reconstrut_freq[:,:,1:,:]-reconstrut_freq[:,:,:w_x-1,:]),2).sum()\n",
    "        \n",
    "        #print(reconstrut_freq.shape)\n",
    "        h_tv_y = torch.pow((capture_freq[:,1:,:,:]-capture_freq[:,:h_x-1,:,:]),2).sum()\n",
    "        w_tv_y = torch.pow((capture_freq[:,:,1:,:]-capture_freq[:,:,:w_x-1,:]),2).sum()\n",
    "        \n",
    "        \n",
    "        count_h = self._tensor_size(x[:,1:,:,:])\n",
    "        count_w = self._tensor_size(x[:,:,1:,:])\n",
    "        \n",
    "        \n",
    "        tv_diff = 2*(h_tv_x/count_h+w_tv_x/count_w)/batch_size - 2*(h_tv_y/count_h+w_tv_y/count_w)/batch_size\n",
    "        print(0.01*tv_diff)\n",
    "        \n",
    "        \n",
    "        \n",
    "        S = torch.ifft(self.batch_ifftshift2d(cEsp),3,normalized=True)\n",
    "        Se = S[:,:,:,0]\n",
    "        \n",
    "        mse = torch.mean(torch.abs(Se-y[:,:,:,0]))/2-0.01*tv_diff\n",
    "        return mse\n",
    "\n",
    "\n",
    "    def _tensor_size(self,t):\n",
    "        return t.size()[1]*t.size()[2]*t.size()[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "discrete wavelet transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dwt_init(x):\n",
    "\n",
    "    x01 = x[:, :, 0::2, :] / 2\n",
    "    x02 = x[:, :, 1::2, :] / 2\n",
    "    x1 = x01[:, :, :, 0::2]\n",
    "    x2 = x02[:, :, :, 0::2]\n",
    "    x3 = x01[:, :, :, 1::2]\n",
    "    x4 = x02[:, :, :, 1::2]\n",
    "    x_LL = x1 + x2 + x3 + x4\n",
    "    x_HL = -x1 - x2 + x3 + x4\n",
    "    x_LH = -x1 + x2 - x3 + x4\n",
    "    x_HH = x1 - x2 - x3 + x4\n",
    "\n",
    "    return torch.cat((x_LL, x_HL, x_LH, x_HH), 1)\n",
    "\n",
    "def iwt_init(x):\n",
    "    r = 2\n",
    "    in_batch, in_channel, in_height, in_width = x.size()\n",
    "    #print([in_batch, in_channel, in_height, in_width])\n",
    "    out_batch, out_channel, out_height, out_width = in_batch, int(\n",
    "        in_channel / (r ** 2)), r * in_height, r * in_width\n",
    "    x1 = x[:, 0:out_channel, :, :] / 2\n",
    "    x2 = x[:, out_channel:out_channel * 2, :, :] / 2\n",
    "    x3 = x[:, out_channel * 2:out_channel * 3, :, :] / 2\n",
    "    x4 = x[:, out_channel * 3:out_channel * 4, :, :] / 2\n",
    "    \n",
    "\n",
    "    h = torch.zeros([out_batch, out_channel, out_height, out_width]).float().cuda()\n",
    "\n",
    "    h[:, :, 0::2, 0::2] = x1 - x2 - x3 + x4\n",
    "    h[:, :, 1::2, 0::2] = x1 - x2 + x3 - x4\n",
    "    h[:, :, 0::2, 1::2] = x1 + x2 - x3 - x4\n",
    "    h[:, :, 1::2, 1::2] = x1 + x2 + x3 + x4\n",
    "\n",
    "    return h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finish the model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.conv_init = nn.Sequential( \n",
    "            nn.Conv2d(2, 16, 5, stride=1, padding=2),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.Conv2d(16, 16, 3, stride=1, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm2d(16),\n",
    "        )\n",
    "        \n",
    "        self.conv_1 = nn.Sequential(   \n",
    "            nn.Conv2d(64, 64, 3, stride=1, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(64, 64, 3, stride=1, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm2d(64),\n",
    "        )\n",
    "        \n",
    "        self.conv_2 = nn.Sequential(   \n",
    "            nn.Conv2d(256, 256, 3, stride=1, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.Conv2d(256, 256, 3, stride=1, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm2d(256),\n",
    "        )\n",
    "        \n",
    "        self.conv_nonlinear = nn.Sequential(   \n",
    "            nn.Conv2d(1024, 1024, 3, stride=1, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.Conv2d(1024, 16, 3, stride=1, padding=1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.deconv_1 = nn.Sequential(\n",
    "            nn.Conv2d(16, 1024, 3, stride=1, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.Conv2d(1024, 1024, 3, stride=1, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm2d(1024),\n",
    "        )\n",
    "        \n",
    "        self.deconv_2 = nn.Sequential(\n",
    "            nn.Conv2d(256, 256, 3, stride=1, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.Conv2d(256, 256, 3, stride=1, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm2d(256),\n",
    "        )\n",
    "        \n",
    "        self.deconv_3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, 3, stride=1, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(64, 64, 3, stride=1, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm2d(64),\n",
    "        )\n",
    "        \n",
    "        self.deconv_4 = nn.Sequential(\n",
    "            nn.Conv2d(16, 16, 3, stride=1, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            #nn.BatchNorm2d(16),\n",
    "            nn.Conv2d(16, 16, 3, stride=1, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            #nn.BatchNorm2d(16),\n",
    "            nn.Conv2d(16, 2, 3, stride=1, padding=1),\n",
    "        )\n",
    "        \n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = x.float()\n",
    "        x = self.conv_init(x)\n",
    "        x = dwt_init(x)\n",
    "        x = self.conv_1(x)\n",
    "        x = dwt_init(x)\n",
    "        x = self.conv_2(x)\n",
    "        x = dwt_init(x)\n",
    "        x = self.conv_nonlinear(x)\n",
    "        \n",
    "        x = self.deconv_1(x)\n",
    "        x = iwt_init(x)\n",
    "        x = self.deconv_2(x)\n",
    "        x = iwt_init(x)\n",
    "        x = self.deconv_3(x)\n",
    "        x = iwt_init(x)\n",
    "        x = self.deconv_4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.current_device())\n",
    "device_default = torch.cuda.current_device()\n",
    "torch.cuda.device(device_default)\n",
    "torch.cuda.get_device_name(device_default)\n",
    "\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.version.cuda)\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.get_arch_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "criterion_1 = RECLoss()\n",
    "model = Net().cuda()\n",
    "optimer_1 = optim.Adam(model.parameters(), lr=5e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "epoch_1 = 5000\n",
    "epoch_2 = 2000\n",
    "period = 100\n",
    "eta = torch.from_numpy(np.concatenate([np.real(eta)[np.newaxis,:,:], np.imag(eta)[np.newaxis,:,:]], axis = 1))\n",
    "holo = torch.from_numpy(np.concatenate([np.real(g)[np.newaxis,:,:], np.imag(g)[np.newaxis,:,:]], axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(epoch_1):\n",
    "    in_img = eta.to(device)\n",
    "    target = holo.to(device)\n",
    "    \n",
    "    out = model(in_img) \n",
    "    l1_loss = criterion_1(out, target)\n",
    "    loss = l1_loss\n",
    "    \n",
    "    \n",
    "    optimer_1.zero_grad()\n",
    "    loss.backward()\n",
    "    optimer_1.step()\n",
    "    \n",
    "    print('epoch [{}/{}]     Loss: {}'.format(i+1, epoch_1, l1_loss.cpu().data.numpy()))\n",
    "    if ((i+1) % period) == 0:\n",
    "        outtemp = out.cpu().data.squeeze(0).squeeze(1)\n",
    "        outtemp = outtemp\n",
    "        plotout = torch.sqrt(outtemp[0,:,:]**2 + outtemp[1,:,:]**2)\n",
    "        plotout = (plotout - torch.min(plotout))/(torch.max(plotout)-torch.min(plotout))\n",
    "        plt.figure(figsize=(20,15))\n",
    "        plt.imshow(tensor2pil(plotout), cmap='gray')\n",
    "        plt.show()\n",
    "        \n",
    "        plotout_p = (torch.atan(outtemp[1,:,:]/outtemp[0,:,:])).numpy()\n",
    "        plotout_p = Phase_unwrapping(plotout_p)\n",
    "        plotout_p = (plotout_p - np.min(plotout_p))/(np.max(plotout_p)-np.min(plotout_p))\n",
    "        plt.figure(figsize=(20,15))\n",
    "        plt.imshow((plotout_p), cmap='gray')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "outtemp = out.cpu().data.squeeze(0).squeeze(1)\n",
    "outtemp = outtemp\n",
    "plotout = torch.sqrt(outtemp[0,:,:]**2 + outtemp[1,:,:]**2)\n",
    "plotout = (plotout - torch.min(plotout))/(torch.max(plotout)-torch.min(plotout))\n",
    "plt.figure(figsize=(30,30))\n",
    "plt.imshow(tensor2pil(plotout), cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plotout_p = (torch.atan(outtemp[1,:,:]/outtemp[0,:,:])).numpy()\n",
    "plotout_p = Phase_unwrapping(plotout_p)\n",
    "plotout_p = (plotout_p - np.min(plotout_p))/(np.max(plotout_p)-np.min(plotout_p))\n",
    "plt.figure(figsize=(30,30))\n",
    "plt.imshow((plotout_p), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#cv2.imwrite(\"./penalty_1/1_amp.png\",tensor2pil(plotout))\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "type(tensor2pil(plotout))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "amp =tensor2pil(plotout)\n",
    "amp.save(\"./penalty_1/1_amp.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cv2.imwrite(\"phase.png\",plotout_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
